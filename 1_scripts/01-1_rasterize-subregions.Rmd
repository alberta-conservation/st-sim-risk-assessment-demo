# Rasterize subregions 

```{r setup, include=FALSE, cache=FALSE}
#Set root directory to R project root
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())


library(RPostgreSQL)
library(sf)
library(tidyverse)
library(terra)

```

An ST-Sim model requires a raster that delineates the study area. In many ST-Sim analyses, there will be >1 sub-region within the main study area, with some parameters and transition probabilities differing between sub-regions. In this demo, I am limiting the analysis to a single Forest Management Unit (FMU) in Alberta, so we are not too worried about sub-regions, but we will go through the process anyway. 

We delineate sub-regions using the **Natural Regions and Sub-regions database** from the Government of Alberta [@naturalregionscommittee2006]. This database is made available here because it if very difficult to find the downloadable shapefile.   

**The Alberta Forest Management Units (FMU) database**, from which we will use FMU L3 can be downloaded from Data Basin [here](https://databasin.org/datasets/606eb8aad3ec4d4fb1406d0159d15280/). Because I will be saving these in the Postgres database, I will convert all the field names to lower case letters. For some reason, Postgres has a hard time working with upper case letters in the field names. 

```{r, eval = FALSE}
nrsa <- st_read("0_data/raw/shapefiles/Natural_Regions_Subregions_of_Alberta/Natural_Regions_Subregions_of_Alberta.shp")
colnames(nrsa) <- tolower(colnames(nrsa))

fmu <- st_transform(st_read("0_data/raw/alberta_fmu/data/data/BF_FMU_POLYGON_10TM/BF_FMU_POLYGON_10TM.shp"), crs = 3400)
colnames(fmu) <- tolower(colnames(fmu))

# Filter the L3 fmu 
fmu_l3 <- fmu %>% filter(fmu_name == "L3")


ggplot() + geom_sf(data = nrsa, aes(fill = NSRNAME)) +
  geom_sf(data = fmu_l3, fill = NA, linewidth = 1)



# Export the fmu layers to Postgres  

# Enter the username and password without putting it into your code
# Note: Once you enter these, they will be visible in your R environment, so I remove them after connecting to the database
username <- rstudioapi::askForPassword("Database username")
password <- rstudioapi::askForPassword("Database password")

pg = dbDriver("PostgreSQL")
# Local Postgres.app database; no password by default
# Of course, you fill in your own database information here.
con = dbConnect(pg, user = username, password = password,
                host = "localhost", port = 5432, dbname = "st_sim_demo")
rm(list = c("username", "password"))

st_write(fmu, con, layer = "alberta_fmu")
st_write(fmu_l3, con, layer = "fmu_l3") 
st_write(nrsa, con, layer = "alberta_natural_subregions") 
st_write(fmu_l3, "0_data/processed/shapefiles/fmu_l3.shp") 

```


We will create the rasters using the 'rasterize' command from the 'terra' package. The first step is to create a template raster from the L3 FMU layer using a 100m cell resolution. Then I will use the template to rasterize the natural sub-regions polygons. 

```{r, eval = FALSE}
# Create the template raster
box <- st_bbox(fmu_l3)

l3_rast <- terra::crop(rast(xmin = box$xmin, xmax = box$xmax, ymin = box$ymin, ymax = box$ymax, crs = crs(fmu), resolution = 100, vals = 1), vect(fmu_l3), mask = TRUE)
plot(l3_rast)



```


```{r, eval = FALSE}
# Create the template raster
box <- st_bbox(nrsa)

ab_rast <- terra::crop(rast(xmin = box$xmin, xmax = box$xmax, ymin = box$ymin, ymax = box$ymax, crs = crs(fmu), resolution = 100, vals = 1), vect(nrsa), mask = TRUE)

nrsa_rast <- terra::rasterize(nrsa, ab_rast, field = "nsrname")
plot(nrsa_rast)
writeRaster(nrsa_rast, "0_data/processed/rasters/ab_natural_subregions.tif")

ab_nr_rast <- terra::rasterize(nrsa, ab_rast, field = "nrname")
plot(ab_nr_rast)
writeRaster(ab_nr_rast, "0_data/processed/rasters/ab_natural_regions.tif") 

l3_nrsa_rast <- terra::crop(nrsa_rast, vect(fmu_l3), mask = TRUE)
plot(l3_nrsa_rast)

freq(l3_nrsa_rast)

```

Although a substantial portion of the study are is in the Lower Boreal Highlands, at this point we will assume constant parameters across the area (i.e., no sub-regions in the model). 




